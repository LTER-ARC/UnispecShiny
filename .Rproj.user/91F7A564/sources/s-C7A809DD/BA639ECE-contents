---
title: "Process Unispec Files collected on One Day"
author: "Ruby An, Jim Laundre"
date: "2021-07-29, 2022-04-16"
output:
  html_notebook:
  html_document:
    df_print: paged
params:
  data:
    label: "Input raw .spu files:"
    value: ""
    input: file 
editor_options: 
  markdown: 
    wrap: 72
---

## Introduction

Code chucks can be run individually and previewed or Run all the chucks
and then check the output for errors or success.

Processing ".spu" unispec data. The \*.spu and Excel key files should
present in the following structure.

-   Folder structure: *rawUnispec/yyyy-mm-dd*

-   \*.spu files under the folder: *sitecode_0000n.spu*

    -   Where *sitecode* is the three letter code for site and two
        number year of experiment and *n* is scan number.

-   Key files: *yyyy-mm-dd_sitecode_template.xlsx*

To plot the raw scan values run this R statement:

runApp("./Visualizations/CheckScans")

## Required Packages & Functions
## Read in data

-   data_path is year folder where the session files are stored. The
    structure is year/spu/yyyy-mm-dd where yyyy-mm-dd is sample date.
    Should be on OneDrive.

-   Field Key file with header
    "Date,Site,Block,Treatment,Replicate,Location,FileNum,Notes,Weather".
    File name convention is year_unispec_field_key.xlsx

```{r setup, include=F}
source("setup.R")
source("read_data.R")

```

## Check data

#### Missing or extra files

Are any measurements location missing their raw spu files?
Any extra.spu files? 
Common problems are key files and .spu files having different site code or
date not entered.

```{r missing, echo=F, warnings=F,results = 'asis'}

# This chunk output 2 tables. The overlap between "field_keys" and "spu_dataframe" finds any (a) missing raw .spu files OR (b) extra .spu files that aren't accounted for in the unispec field keys.

missing_info <- raw_data %>% 
  filter(is.na(spu_filename) | 
         is.na(Site) |
          # Block with NA's should always be REFS or EXTRA 
         is.na(Block) & !str_detect(Treatment, "REF|DARK|VEG") | 
          # Check for replicates with NA's that aren't REF
         is.na(Replicate) & !str_detect(Treatment, "REF|DARK|THROWAWAY"),
         # don't care about EXTRA, VEG, or REF scans
         Treatment != "EXTRA|VEG|REF") %>%
   # reorder columns to see output better
  select(spu_filename, FileNum, Site, Block, Treatment, Replicate, everything())

# Identify any files that aren't listed in the field key

extra_files <- anti_join(spu_dataframe, field_keys,by = c("Date", "FileNum", "Site")) %>%
    pull(spu_filename)

# Check File Number Pattern -- The number of files per block should be multiples of 5, with exception of REF or NA. 
df_filenum_count <- field_keys %>% group_by(Site, Date, Block, Treatment) %>% 
    summarize(Num_Files = n(),.groups = "keep") %>% # count the number of files
    filter(Num_Files %% 5 != 0) %>%   # files per plot
    # Remove scans that aren't of plot locations (DARK, REF, THROWAY)
    filter(Treatment != "THROWAWAY") %>% 
    filter(Treatment != "DARK") %>% 
    filter(! "REF" %in% Treatment)
# Check site names are equal in .spu files names and key file.

spu_sites <-  str_c(str_replace_na(unique(spu_dataframe$Site)), collapse = ",")
key_sites <-  str_c(str_replace_na(unique(field_keys$Site)), collapse = ",")

# Create a multi-table kables object
check_tables <- kables(
  list(
    kable(tibble(Description=c("Total number of .spu files: ",
                               "Total number of scans documented in key file: ",
                     "Scan Locations missing from key file: ","Plots with scans not a multiple of 5: ",
                     "Sites from .spu file prefixes: ", "Sites from key file:"),
       Value=c(nrow(spu_dataframe),nrow(field_keys),nrow(missing_info),NROW(extra_files),
               spu_sites,
               key_sites)
    )),

  kable((raw_data %>% group_by(Date, Site, Block) %>%  
    filter(!is.na(Treatment)) %>% 
    summarize(Treatments = str_c(str_replace_na(sort(unique(Treatment))), 
                                 collapse = ","), Num_Files = n(), .groups = "keep")), 
    caption ="Number of files listed in field key")
  ), caption = "Checks on the number of files and sites"
)
check_tables
if (spu_sites!= key_sites) {
     cat(paste('**The site names between the .spu filenames and in the key file do not match!**',
                  ".spu: ",spu_sites,"key:", key_sites))
}
```


```{r abort_if_missing, echo=F, warnings=F,results = 'asis'}

if(any(is.na(missing_info$spu_filename_full))) {
  cat(paste('**There are Key File entries without .spu files**',  'Check previous tables for unexpected results.',sep = "\n"),"\n")
  file.remove (paste0(tools::file_path_sans_ext(rstudioapi::getActiveDocumentContext()$path),".nb.html"))
  stop("Missing .spu files. Run aborted")
}
```

### QAQC: Instrument Check

### Max'd Out Spectra (> 65000 AD)

List files that maxed out, in the wavelengths used to calculate MODIS
NDVI.

```{r maxed, echo=F, dependson="raw_data", fig.show="hold", out.width="50%"}

maxed_files <- raw_data %>% inner_join(spu_dataframe %>% select(spu_filename),by = "spu_filename") %>% # restrict to those w/.spu files
  unnest(Spectra) %>% 
  filter(ChA > 65000 | ChB > 65000) %>% 
  select(spu_filename) %>%
  unique()
 # summarize(maxed_number = n(), maxed_wavelengths = str_c(min(Wavelength), " - ", max(Wavelength), collapse = ", "))  

if (nrow(maxed_files) > 0 ){
  max_data <- raw_data %>% 
  filter(spu_filename %in% maxed_files$spu_filename) %>%
  unnest(Spectra) %>%
  mutate(Reflectance = ChB/ChA) %>% 
  filter(Wavelength > 400, Wavelength < 1000)
  #Graph maxed out spectra
 (p1<-max_data %>% gather(key = Channel, value = Intensity, ChB, ChA) %>%
  gather(key = ref_part, value = Reflectance_Intensity, Intensity, Reflectance) %>% 
  ggplot(mapping = aes(x = Wavelength, y = Reflectance_Intensity)) +
    geom_line(aes(color=Channel)) +
    facet_wrap(~ spu_filename, nrow = 4))
# Print MAXED files 
  maxed_data <- max_data %>% 
    filter(ChA > 65000 | ChB > 65000) %>% 
    group_by(spu_filename) %>%
    summarize(number_of_maxed_wavelength = n(), maxed_wavelengths = str_c(min(Wavelength),
                                                " - ", max(Wavelength), collapse = ", ")) 
   # Maxed file list 
  raw_data %>% select(spu_filename, Site, Date, Block, Treatment, Replicate) %>% 
     inner_join(maxed_data,by = "spu_filename") %>%
     kable(align = "c", caption = "Files with maxed out wavelegnth" )

  #if (menu(c("Yes", "No"), title="Replace maxed with NA?",graphics = T)){
    raw_data <- raw_data %>%
      unnest(Spectra)%>%
      mutate(ChA = replace(ChA, ChA > 65000, NA), ChB = replace(ChB,ChB > 65000, NA)) %>%
      nest(Spectra = c(Wavelength, ChB, ChA))
  #}
 } else { print("no maxed files")}
```

## Correct data with Reference files

White references correct for instrument & cable irregularities.
Multiplying by the correction factor (ChA/ChB) smooths out the spectra.
There are typically 5 reference measurements per *Date* / *Site*. If
multiple file numbers are listed, the correction factors are averaged.

Make sure to rerun the **Read Unispec Keys** if you change REF file
choices. The following code plots your chosen references for a visual
check.

### Choose & Check References

```{r ref_choice_list, echo=F}
## INPUTS:
# - raw_data, including the reference files

# OUTPUT:
# - correction_factors data_frame
# - plot to see the plot of the white reference files


# Create a vector of reference files (by treatment labels)
ref_files <- raw_data %>% 
  filter(Treatment == "REF") %>% 
  select(spu_filename) %>% 
  pull()

#Check for sites or treatments without reference files
if(any(is.na(ref_files))) {
  warning("Missing reference files")
  stop(paste("",ref_files,sep = "\n"))
}
#missing_ref <- raw_data %>% 

ref_data <- raw_data %>%
  ## Get the spectra for reference files
  filter(Treatment == "REF") %>%
  ### Unnest Spectra & calculate correction factor
  unnest(Spectra) %>%
  filter(Wavelength > 400, Wavelength < 1000) %>% # remove edge wavelengths, instrument unreliable at extremes
  mutate(correction_factor = ChA / ChB) %>%
  ### Group repeated REF measurements based on your plot set-up (choose Block or NOT)
  group_by(Date, Site, Integration, Wavelength)

## Calculate correction factors by averaging 5 chosen ref measurements per DATE/SITE & calculate mean correction factors
correction_factors <- ref_data %>% 
  summarize(correction_factor = mean(ChA/ChB), 
            ref_filenames = str_c(spu_filename,collapse = ", ")) 

## QUALITY CHECK
## Table per Site of Reference Files 
(ref_filenames_table <- ref_data %>% group_by(Date, Site, Integration) %>% 
  summarize(Files = n_distinct(spu_filename), ref_filenames = str_c(spu_filename,collapse = ", ")) )


### VIZ
(ref_plot <- ggplot(ref_data,
                    aes(x = Wavelength, 
                        y = correction_factor,
                        group_by = spu_filename)) + 
  theme(legend.position="left") + 
  geom_line(aes(color=factor(Integration))) + 
  
  # Formatting
  labs(title = "White Reference Correction Factor",
       subtitle = "Make sure correction factor isn't a data scan and between 0.5 and 1.5",
       x = "Wavelength (nm)", 
       y = "Correction Factor") + 
  scale_linetype_discrete(name = "Files") + 
  scale_color_discrete(name = "Integration Time") + 
    geom_hline(yintercept = 0.5, lty = 2) +
    geom_hline(yintercept = 1.5, lty = 2) +
  theme_light()
  
  ) 

(ref_plot1 <- ggplot(ref_data,aes(x = Wavelength, y = correction_factor,
                        group_by = spu_filename)) + 
     theme(legend.position="left") + 
     geom_line(aes(color=factor(FileNum))) +
    scale_color_discrete(name ="File Number") +
     facet_grid(Site ~ Treatment) +
      # Formatting
  labs(title = "White Reference Raw Scan",
       subtitle = "They all should be very similar.",
       x = "Wavelength (nm)", 
       y = "Raw Reflectance")
)
plotly::ggplotly(ref_plot1)
```

## Process Data

Apply references to the data scans. Rerun the **Join Data & keys**
sections above to update the `raw_data` dataframe. Apply your chosen
references to actual spectral data to create the tidy dataframe
`processed_data` containing corrected spectral reflectance values.

INPUTS: - raw_data - correction_factors

OUTPUT: - processed_data - plot of first 30 files to check

```{r apply_refs, echo=FALSE}

#------ 
# Get integration times of ref data for each site
ref_int_values <- raw_data %>%
  filter((spu_filename %in% ref_files)) %>%
  select(Date,Site,Integration) %>%
  distinct()
# Join reference scan integration time to the nearest data scan integration time
raw_data_with_ref_int <- inner_join(raw_data, ref_int_values, by = c("Date","Site"),suffix = c(".data",".ref")) %>%
  group_by(Date,Site,FileNum) %>%
  mutate(Integration.ref = Integration.ref[which.min(abs(Integration.data-Integration.ref))]) %>%
  distinct(FileNum, .keep_all = TRUE)

## Join DATA with REFS

raw_data_with_refs <- raw_data_with_ref_int %>% 
  
  # unlist Spectra and remove edge wavelengths, because instrument unreliable at extreme wavelengths
  unnest(Spectra) %>% 
  filter(Wavelength > 400, Wavelength < 1000) %>%
  # 
  # # assign the "REF_Integration" value closest to data scan integration time
   rowwise() %>%
   group_by(Date, Site, Integration.ref) %>%
  # mutate(REF_Integration = ref_int_values$Integration[sapply(Integration, function(x)      #which.min(abs(ref_int_values$Integration - x)))]) %>%
  # #mutate(REF_Integration = assign_closest_ref(Integration, ref_int_values)) %>% 
  #ungroup() %>% 
  # join data with ref data
  left_join(.,correction_factors %>% rename(Integration.ref = Integration), 
            by = c("Date", "Site", "Wavelength", "Integration.ref")) %>%
  #select(-Integration.ref) %>%  # drop joining column, no longer needed
  ungroup() %>% 
  # calculate reflectances
  mutate(raw_reflectance = ChB/ChA) %>% # the raw reflectance
  mutate(corrected_reflectance = raw_reflectance*correction_factor) # corrected reflectance
X<- raw_data_with_refs %>% filter(is.na(correction_factor)) %>% filter( !Treatment=="IGNOR")

## Corrected Reflectances with one row per file
processed_data <- raw_data_with_refs %>% 
  nest(processed_spectra = c(Wavelength, ChB, ChA, correction_factor, raw_reflectance, corrected_reflectance))
```

### QAQC application

```{r check_data, echo=F}

## Check all files have a corrected reflectance

missing_corrections <- processed_data %>%  filter(processed_spectra %>% map(is.null) %>% map_lgl(any)) # remove files w/out spu_spectra

corrected_spectra_files <- processed_data %>% 
  unnest(processed_spectra) %>% 
  filter(!is.na(corrected_reflectance)) %>% # check the column is calculated
  select(spu_filename, Date, Site) %>% distinct()


print(paste0("Number of raw files: ", nrow(raw_data)))
print(paste0("Number of corrected Files: ", nrow(corrected_spectra_files)))

## print treatments missing corrections
if(nrow(processed_data) != nrow(raw_data)) {
  anti_join(raw_data, corrected_spectra_files) %>% 
  group_by(Date, Site, Block, Treatment, Integration) %>% 
  summarize(Num_Files = n()) %>% kable()
  
  anti_join(raw_data, processed_data, by = "spu_filename") %>% pull(Treatment) %>% unique() %>% print()
  
  print(missing_corrections)
}

##### VIZ: Plot Check first 30 files

plot_data <- processed_data %>% 
    filter(Treatment %in% c("DARK", "REF", "CT", "CT1", "CT2")) %>% 
   
  unnest(processed_spectra) %>% 
  gather(key = Status, value = Reflectance, raw_reflectance, corrected_reflectance) 
  
  # VIZ
  ggplot(plot_data,mapping = aes(x = Wavelength, y = Reflectance )) + 
  geom_line(aes(color = spu_filename, linetype = Status)) +
    facet_grid(Site ~ Treatment) +
  theme_light()+
  theme(legend.position = "none")

```

## Calculate INDICES

Currently, this only works for NDVI, EVI, and EVI2 as I haven't worked
out spectral interpolation yet and the other indices need reflectance at
a specific value (not a range).

### Calculate Indices

```{r calculate_indices, echo=F}

index_data <- processed_data %>% 
  
  ## Format for calculuating indices function
  unnest(processed_spectra) %>%
  select(-ChB, -ChA, -raw_reflectance, -correction_factor) %>%
  rename(Reflectance = corrected_reflectance) %>%
  nest(Spectra = c(Wavelength, Reflectance)) %>%
  
  ## Calculate NDVI
  mutate(Indices = map(Spectra, function(x) calculate_indices(x, band_defns = band_defns, instrument = "MODIS", indices = c("NDVI", "EVI", "EVI2"))))


```

### QAQC: Visualize with other years

```{r plot_data, echo=F}
## Convert current data format for visualization

viz_data <- index_data %>%
    select(-Spectra) %>% 
    unnest(Indices) %>% 
  
    select(-BandDefinition) %>%
    spread(Index, Value) %>%

    # Select useful columns 
    select(DateTime, Date, Site, Block, Treatment, Replicate, FileNum, NDVI, EVI, EVI2) %>%
  
    # Create additional columns 
    mutate(Year = lubridate::year(DateTime),
           DOY = lubridate::yday(DateTime)) %>%
    rename(Time = DateTime) %>%
    mutate(Block = as.numeric(str_extract(Block, "\\d"))) %>%
    mutate(Replicate = as.character(Replicate)) %>% 
    mutate(collection_year = "current") %>% 
  
    # remove non-data (ref, dark, throwaway) scans
    filter(!str_detect(Treatment, "REF|DARK|THROWAWAY"))

# Get relevant treatments and sites
viz_treatments <- viz_data$Treatment %>% unique()
viz_sites <- viz_data$Site   %>% unique()

# Read data from past years
past_data <- (if (file.exists("indices_2014-2019.updated.rds")){
                   readRDS("indices_2014-2019.updated.rds")
                }else{
                   readRDS(selectFile(caption = "Select Past years indices .rds file"))
                 })%>% 
  
    # Standardize Site names from 2019 version to 2020 onwards
    mutate(Site = ifelse(Site %in% c("WSG1", "WSG23"), "WSG89", Site))  %>%
    mutate(Site = ifelse(Site %in% c("DHT"), "DHT89", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("MAT"), "MAT89", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("LMAT"), "MAT06", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("HIST"), "DHT89", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("SHB2"), "SHB89", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("MNAT"), "MNT97", Site)) %>% 
    mutate(Site = ifelse(Site %in% c("NANT"), "MNN97", Site)) %>% 
  
    # Label as previous years
    mutate(collection_year = "Past") %>% 
  
  # Get relevant subset of data
  filter(Treatment %in% viz_treatments) %>% 
  filter(Site %in% viz_sites) %>% 
  filter(Year >= 2017) 


all_data <- past_data %>% 
  full_join(viz_data) %>%
  
  # Calculate mean +/- se
  group_by(Site, DOY, Date, Treatment, collection_year) %>% 
  summarise(sd = sd(NDVI,na.rm = T),
            NDVI = mean(NDVI, na.rm = T)) %>% 
  
# standardize site names
  mutate(Site = ifelse(Site %in% c("NANT", "NNT97"), "MNN97", Site))

(plot <- ggplot(data = all_data, aes(x = DOY,
                                     y = NDVI,
                                     color = collection_year)) +
    geom_point(aes(alpha = 0.5)) +
    facet_grid(Site ~ Treatment) +

    #formatting
    theme_minimal() +
    scale_color_manual(values = c("red", "grey"))
)


```

## SAVE DATA

```{r save_files, echo=F}
# ## Set base file name
 base_filename <- paste0(data_path, "/", processed_data$Date[1])
# Save corrected reflectance data 
 write_rds(processed_data, paste0(base_filename, "_processed_spu_data.rds"))
# ## Save index data
 write_rds(index_data, paste0(base_filename, "_index_data.rds"))
# Save csv file of just NDVI, EVI, and EVI2 indexs
 write.csv(viz_data, file= paste0(base_filename,"index.csv"))
```
